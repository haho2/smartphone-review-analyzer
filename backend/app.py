from flask import Flask, request, jsonify
from flask_cors import CORS
import ai_service  # ë°©ê¸ˆ ì´ë¦„ ë°”ê¾¼ íŒŒì¼(ai_service.py)ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤
import database  # MongoDB ìºì‹± ë ˆì´ì–´
import crawler  # ìœ íŠœë¸Œ ê²€ìƒ‰ ë° ì»¤ë®¤ë‹ˆí‹° í¬ë¡¤ë§
import os
import threading
import json

app = Flask(__name__)
# í”„ë¡ íŠ¸ì—”ë“œ(React)ì—ì„œ ìš”ì²­ì„ ë³´ë‚¼ ë•Œ ë³´ì•ˆ ë¬¸ì œë¥¼ í•´ê²°í•´ì¤ë‹ˆë‹¤.
CORS(app)

# êµ¬ë§¤ ê°€ì´ë“œ ìƒì„± ìƒíƒœ ì €ì¥ (ë©”ëª¨ë¦¬ ê¸°ë°˜, ë°ëª¨ìš©)
# êµ¬ì¡°: { "ì œí’ˆëª…": {"status": "processing"|"completed", "guide": {...}, "error": "..."} }
purchase_guide_cache = {}
purchase_guide_lock = threading.Lock() 

@app.route('/')
def home():
    return "AI ë¦¬ë·° ë¶„ì„ ì„œë²„ê°€ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤! ğŸš€"

@app.route('/api/analyze', methods=['POST'])
def analyze_video():
    """
    í”„ë¡ íŠ¸ì—”ë“œì—ì„œ { "video_id": "..." } ë°ì´í„°ë¥¼ ë³´ë‚´ë©´
    AI ë¶„ì„ ê²°ê³¼ë¥¼ ëŒë ¤ì£¼ëŠ” APIì…ë‹ˆë‹¤.
    
    ë™ì‘ íë¦„:
    1. MongoDBì—ì„œ ìºì‹œ í™•ì¸ (Cache Hit/Miss)
    2. Hit: ì¦‰ì‹œ ë°˜í™˜
    3. Miss: AI ë¶„ì„ ìˆ˜í–‰ â†’ DB ì €ì¥ â†’ ë°˜í™˜
    """
    data = request.get_json()
    video_id = data.get('video_id')

    if not video_id:
        return jsonify({"error": "video_idê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

    print(f"ğŸ“¡ ìš”ì²­ ìˆ˜ì‹ : ë¹„ë””ì˜¤ ID [{video_id}] ë¶„ì„ ì‹œì‘...")

    # 1. MongoDB ìºì‹œ í™•ì¸ (Cache Hit ì²´í¬)
    cached_result = database.get_review_from_db(video_id)
    
    if cached_result:
        # ìºì‹œ íˆíŠ¸: ì €ì¥ëœ ë¶„ì„ ê²°ê³¼ ì¦‰ì‹œ ë°˜í™˜
        print(f"   âš¡ ìºì‹œì—ì„œ ê²°ê³¼ ë°˜í™˜ (ìƒì„± ì‹œê°„: {cached_result.get('created_at', 'N/A')})")
        return jsonify({
            "video_id": video_id,
            "analysis": cached_result.get('analysis', ''),
            "cached": True
        })

    # 2. ìºì‹œ ë¯¸ìŠ¤: AI ë¶„ì„ ìˆ˜í–‰
    print(f"   ğŸ”„ ìºì‹œ ë¯¸ìŠ¤: AI ë¶„ì„ ì‹œì‘...")
    
    # 2-1. ìë§‰ ê°€ì ¸ì˜¤ê¸° (ai_serviceì˜ í•¨ìˆ˜ ì‚¬ìš©)
    script = ai_service.get_youtube_script(video_id)
    
    if script.startswith("âŒ"):
        return jsonify({"error": script}), 500

    # 2-2. Gemini ë¶„ì„ (ai_serviceì˜ í•¨ìˆ˜ ì‚¬ìš©)
    result = ai_service.analyze_with_gemini(script)

    if result.startswith("âŒ"):
        return jsonify({"error": result}), 500

    # 3. ë¶„ì„ ê²°ê³¼ë¥¼ MongoDBì— ì €ì¥ (ìºì‹±)
    database.save_review_to_db(video_id, result)

    # 4. ì„±ê³µ ê²°ê³¼ ë°˜í™˜
    return jsonify({
        "video_id": video_id,
        "analysis": result,
        "cached": False
    })


@app.route('/api/analyze-product', methods=['POST'])
def analyze_product():
    """
    ì œí’ˆëª…ì„ ë°›ì•„ì„œ ìœ íŠœë¸Œ ì˜ìƒ 3ê°œì™€ ì»¤ë®¤ë‹ˆí‹° í›„ê¸°ë¥¼ ì¢…í•© ë¶„ì„í•˜ëŠ” API
    
    Request Body:
    {
        "product_name": "ê°¤ëŸ­ì‹œ S25"
    }
    
    Response:
    {
        "product_name": "ê°¤ëŸ­ì‹œ S25",
        "youtube_reviews": [
            {"video_id": "...", "title": "...", "analysis": "..."},
            ...
        ],
        "community_reviews": {
            "summary": "...",
            "raw_count": 10
        },
        "purchase_guide": "..."
    }
    """
    data = request.get_json()
    product_name = data.get('product_name')
    
    if not product_name:
        return jsonify({"error": "product_nameì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400
    
    print(f"ğŸ“¡ ìš”ì²­ ìˆ˜ì‹ : ì œí’ˆëª… [{product_name}] ì¢…í•© ë¶„ì„ ì‹œì‘...")
    
    try:
        # ì œí’ˆëª… ì •ê·œí™” (Fuzzy ë§¤ì¹­ìœ¼ë¡œ ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ëª¨ë¸ë§Œ ë°˜í™˜)
        import product_normalizer
        normalized_product_name = product_normalizer.normalize_product_name(product_name, use_fuzzy_matching=True)
        
        # ì •ê·œí™” ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë°˜í™˜
        if not normalized_product_name:
            return jsonify({"error": f"'{product_name}'ì— í•´ë‹¹í•˜ëŠ” ì œí’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 404
        
        if normalized_product_name != product_name:
            print(f"   â†’ ì •ê·œí™”: {product_name} -> {normalized_product_name}")
        
        # 1. ìœ íŠœë¸Œ ì˜ìƒ ì¡°íšŒ (DB ìš°ì„ , ì—†ìœ¼ë©´ ì‹¤ì‹œê°„ ê²€ìƒ‰)
        print(f"   ğŸ” ìœ íŠœë¸Œ ì˜ìƒ ì¡°íšŒ ì¤‘...")
        
        # DBì—ì„œ ë¨¼ì € ì¡°íšŒ ì‹œë„ (ì •ê·œí™”ëœ ì´ë¦„ìœ¼ë¡œ)
        import batch_crawler
        youtube_videos_from_db = batch_crawler.get_youtube_videos_from_db(normalized_product_name)
        
        if youtube_videos_from_db:
            print(f"   âš¡ DBì—ì„œ ìœ íŠœë¸Œ ì˜ìƒ ì¡°íšŒ ì„±ê³µ ({len(youtube_videos_from_db)}ê°œ)")
            youtube_videos = youtube_videos_from_db
        else:
            # DBì— ì—†ìœ¼ë©´ ì‹¤ì‹œê°„ ê²€ìƒ‰ (ì‚¬ìš©ì ì…ë ¥ ê·¸ëŒ€ë¡œ ì‚¬ìš©)
            print(f"   ğŸ”„ DBì— ì—†ìŒ: ì‹¤ì‹œê°„ ê²€ìƒ‰ ì‹œì‘...")
            youtube_videos = crawler.search_youtube_top3(product_name)  # ì›ë³¸ ì…ë ¥ ì‚¬ìš©
            
            # ê²€ìƒ‰ ì„±ê³µ ì‹œ DBì— ì €ì¥ (ì •ê·œí™”ëœ ì´ë¦„ìœ¼ë¡œ ì €ì¥)
            if youtube_videos:
                batch_crawler.save_youtube_videos_to_db(normalized_product_name, youtube_videos)
        
        if not youtube_videos:
            return jsonify({"error": "ìœ íŠœë¸Œ ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 404
        
        print(f"   âœ… {len(youtube_videos)}ê°œ ì˜ìƒ ë°œê²¬")
        
        # 2. ê° ì˜ìƒ ë¶„ì„ (ìºì‹œ í™•ì¸ í¬í•¨)
        youtube_analyses = []
        youtube_summaries = []
        
        for video in youtube_videos:
            video_id = video['id']
            video_title = video['title']
            
            print(f"   ğŸ“¹ ì˜ìƒ ë¶„ì„ ì¤‘: {video_title[:50]}...")
            
            # ìºì‹œ í™•ì¸
            cached_result = database.get_review_from_db(video_id)
            
            if cached_result:
                analysis_raw = cached_result.get('analysis', '')
                # ìºì‹œëœ ë°ì´í„°ê°€ JSON ë¬¸ìì—´ì¸ ê²½ìš° íŒŒì‹±
                import json
                try:
                    if isinstance(analysis_raw, str):
                        analysis = json.loads(analysis_raw)
                    else:
                        analysis = analysis_raw
                except:
                    analysis = analysis_raw
                print(f"      âš¡ ìºì‹œ íˆíŠ¸")
            else:
                # ìë§‰ ì¶”ì¶œ ë° ë¶„ì„
                script = ai_service.get_youtube_script(video_id)
                if script.startswith("âŒ"):
                    print(f"      âŒ ìë§‰ ì¶”ì¶œ ì‹¤íŒ¨: {script}")
                    continue
                
                analysis = ai_service.analyze_with_gemini(script)
                if isinstance(analysis, str) and analysis.startswith("âŒ"):
                    print(f"      âŒ ë¶„ì„ ì‹¤íŒ¨: {analysis}")
                    continue
                
                # ìºì‹œ ì €ì¥ (JSON ë˜ëŠ” í…ìŠ¤íŠ¸ ëª¨ë‘ ì €ì¥ ê°€ëŠ¥)
                import json
                if isinstance(analysis, dict):
                    database.save_review_to_db(video_id, json.dumps(analysis, ensure_ascii=False))
                else:
                    database.save_review_to_db(video_id, analysis)
            
            # ë¶„ì„ ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ì €ì¥
            youtube_analyses.append({
                "video_id": video_id,
                "title": video_title,
                "analysis": analysis  # dict ë˜ëŠ” str
            })
            
            # êµ¬ë§¤ ê°€ì´ë“œ ìƒì„±ì„ ìœ„í•œ ìš”ì•½ (í…ìŠ¤íŠ¸ í˜•íƒœ)
            if isinstance(analysis, dict):
                summary_text = f"ì¥ì : {', '.join(analysis.get('pros', []))}\në‹¨ì : {', '.join(analysis.get('cons', []))}"
            else:
                summary_text = str(analysis)
            youtube_summaries.append(summary_text)
        
        # 3. ì»¤ë®¤ë‹ˆí‹° í›„ê¸° ì¡°íšŒ (DB ìš°ì„ , ì—†ìœ¼ë©´ ì‹¤ì‹œê°„ í¬ë¡¤ë§)
        print(f"   ğŸŒ ì»¤ë®¤ë‹ˆí‹° í›„ê¸° ì¡°íšŒ ì¤‘...")
        
        # DBì—ì„œ ë¨¼ì € ì¡°íšŒ ì‹œë„ (ì •ê·œí™”ëœ ì´ë¦„ìœ¼ë¡œ)
        import batch_crawler
        # ì •ê·œí™”ëœ ì´ë¦„ìœ¼ë¡œ DB ì¡°íšŒ (ë” ì •í™•í•œ ë§¤ì¹­)
        # ë°˜í™˜ê°’: (reviews_text, sources, analysis_summary)
        result = batch_crawler.get_community_reviews_from_db(normalized_product_name)
        
        if len(result) == 3:
            community_reviews_text, community_sources, cached_analysis = result
        else:
            # í•˜ìœ„ í˜¸í™˜ì„±
            community_reviews_text, community_sources = result[:2]
            cached_analysis = None
        
        if community_reviews_text:
            print(f"   âš¡ DBì—ì„œ ì»¤ë®¤ë‹ˆí‹° í›„ê¸° ì¡°íšŒ ì„±ê³µ ({len(community_reviews_text.split(chr(10)))}ê°œ)")
        else:
            # DBì— ì—†ìœ¼ë©´ ì‹¤ì‹œê°„ í¬ë¡¤ë§ (Fallback)
            print(f"   ğŸ”„ DBì— ì—†ìŒ: ì‹¤ì‹œê°„ í¬ë¡¤ë§ ì‹œì‘...")
            community_reviews_result = crawler.crawl_community_reviews(product_name)
            
            if isinstance(community_reviews_result, tuple):
                if len(community_reviews_result) == 3:
                    community_reviews_text, community_sources, _ = community_reviews_result
                else:
                    community_reviews_text, community_sources = community_reviews_result
            else:
                community_reviews_text = community_reviews_result
                community_sources = []
            
            # í¬ë¡¤ë§ ì„±ê³µ ì‹œ DBì— ì €ì¥ (ë‹¤ìŒ ìš”ì²­ì„ ìœ„í•´)
            if community_reviews_text and "ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤" not in community_reviews_text:
                # ì‹¤ì œ ê°œìˆ˜ ì¶”ì¶œ (ë¦¬ìŠ¤íŠ¸ì—ì„œ)
                actual_count = len([line for line in community_reviews_text.split('\n') if line.strip().startswith('[')])
                batch_crawler.save_community_reviews_to_db(normalized_product_name, community_reviews_text, community_sources, actual_count)
            cached_analysis = None
        
        # ì»¤ë®¤ë‹ˆí‹° í›„ê¸° ë¶„ì„ (ìºì‹œ í™•ì¸)
        community_summary = None
        if community_reviews_text and "ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤" not in community_reviews_text:
            # ìºì‹œëœ ë¶„ì„ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì‚¬ìš©
            if cached_analysis:
                print(f"   âš¡ DBì—ì„œ ì»¤ë®¤ë‹ˆí‹° ë¶„ì„ ê²°ê³¼ ìºì‹œ íˆíŠ¸")
                import json
                try:
                    if isinstance(cached_analysis, str):
                        community_summary = json.loads(cached_analysis)
                    else:
                        community_summary = cached_analysis
                except:
                    community_summary = cached_analysis
            else:
                # ìºì‹œ ì—†ìœ¼ë©´ AI ë¶„ì„ ìˆ˜í–‰
                print(f"   âœ… ì»¤ë®¤ë‹ˆí‹° í›„ê¸° ìˆ˜ì§‘ ì™„ë£Œ, AI ë¶„ì„ ì‹œì‘...")
                community_summary = ai_service.analyze_community_reviews_with_gemini(community_reviews_text)
                
                # dictê°€ ì•„ë‹Œ ê²½ìš° (ì˜¤ë¥˜ ë“±) ì²˜ë¦¬
                if isinstance(community_summary, str) and community_summary.startswith("âŒ"):
                    community_summary = None
                else:
                    # ë¶„ì„ ì„±ê³µ ì‹œ DBì— ìºì‹±
                    if community_summary:
                        batch_crawler.save_community_analysis_to_db(normalized_product_name, community_summary)
                        print(f"   âœ… ì»¤ë®¤ë‹ˆí‹° ë¶„ì„ ì™„ë£Œ ë° ìºì‹œ ì €ì¥")
        else:
            community_summary = None
        
        # 4. êµ¬ë§¤ ê°€ì´ë“œëŠ” ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¹„ë™ê¸° ìƒì„±
        print(f"   ğŸ“Š êµ¬ë§¤ ê°€ì´ë“œ ìƒì„± ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ)...")
        
        # êµ¬ë§¤ ê°€ì´ë“œ ìƒì„± ìƒíƒœ ì´ˆê¸°í™”
        with purchase_guide_lock:
            purchase_guide_cache[normalized_product_name] = {"status": "processing"}
        
        # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ êµ¬ë§¤ ê°€ì´ë“œ ìƒì„±
        def generate_guide_async():
            try:
                youtube_combined = "\n\n---\n\n".join(youtube_summaries)
                community_text = ""
                if isinstance(community_summary, dict):
                    community_text = f"ì¥ì : {', '.join(community_summary.get('pros', []))}\në‹¨ì : {', '.join(community_summary.get('cons', []))}"
                elif community_summary:
                    community_text = str(community_summary)
                
                guide = ai_service.generate_purchase_guide(
                    youtube_combined,
                    community_text,
                    normalized_product_name
                )
                
                # ê²°ê³¼ ì €ì¥
                with purchase_guide_lock:
                    purchase_guide_cache[normalized_product_name] = {
                        "status": "completed",
                        "guide": guide
                    }
                print(f"   âœ… êµ¬ë§¤ ê°€ì´ë“œ ìƒì„± ì™„ë£Œ: {normalized_product_name}")
            except Exception as e:
                print(f"   âŒ êµ¬ë§¤ ê°€ì´ë“œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
                with purchase_guide_lock:
                    purchase_guide_cache[normalized_product_name] = {
                        "status": "error",
                        "error": str(e)
                    }
        
        # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ ì‹œì‘
        guide_thread = threading.Thread(target=generate_guide_async, daemon=True)
        guide_thread.start()
        
        # 5. ê²°ê³¼ ë°˜í™˜ (êµ¬ë§¤ ê°€ì´ë“œ ì œì™¸)
        return jsonify({
            "product_name": product_name,
            "youtube_reviews": youtube_analyses,
            "community_reviews": {
                "summary": community_summary,  # dict ë˜ëŠ” None
                "raw_count": len(community_reviews_text.split('\n')) if community_reviews_text else 0,
                "source": ", ".join(community_sources) if community_sources else "ìˆ˜ì§‘ ì‹¤íŒ¨",
                "note": "í´ë¦¬ì•™ê³¼ ë½ë¿Œ ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ì§ì ‘ ìˆ˜ì§‘í•œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì‚¬ìš©ì í›„ê¸°ì…ë‹ˆë‹¤."
            },
            "purchase_guide_status": "processing"  # êµ¬ë§¤ ê°€ì´ë“œëŠ” ë³„ë„ ì—”ë“œí¬ì¸íŠ¸ë¡œ í™•ì¸
        })
        
    except Exception as e:
        print(f"   âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return jsonify({"error": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}), 500


@app.route('/api/purchase-guide/<product_name>', methods=['GET'])
def get_purchase_guide(product_name):
    """
    êµ¬ë§¤ ê°€ì´ë“œ ìƒì„± ìƒíƒœ ë° ê²°ê³¼ ì¡°íšŒ (í´ë§ìš©)
    
    Response:
    {
        "status": "processing" | "completed" | "error",
        "guide": {...} (statusê°€ completedì¼ ë•Œë§Œ),
        "error": "..." (statusê°€ errorì¼ ë•Œë§Œ)
    }
    """
    import product_normalizer
    normalized_product_name = product_normalizer.normalize_product_name(product_name, use_fuzzy_matching=True)
    
    if not normalized_product_name:
        return jsonify({
            "status": "error",
            "error": f"'{product_name}'ì— í•´ë‹¹í•˜ëŠ” ì œí’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        }), 404
    
    with purchase_guide_lock:
        cached = purchase_guide_cache.get(normalized_product_name)
    
    if not cached:
        return jsonify({
            "status": "not_started",
            "message": "êµ¬ë§¤ ê°€ì´ë“œ ìƒì„±ì´ ì‹œì‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        }), 404
    
    if cached["status"] == "processing":
        return jsonify({
            "status": "processing",
            "message": "êµ¬ë§¤ ê°€ì´ë“œë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."
        })
    elif cached["status"] == "completed":
        return jsonify({
            "status": "completed",
            "guide": cached["guide"]
        })
    else:  # error
        return jsonify({
            "status": "error",
            "error": cached.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
        }), 500


if __name__ == '__main__':
    # ì„œë²„ ì‹¤í–‰
    # ë°°í¬ í™˜ê²½ì—ì„œëŠ” PORT í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš© (Railway, Render ë“±)
    port = int(os.environ.get('PORT', 5000))
    debug_mode = os.environ.get('FLASK_DEBUG', 'False').lower() == 'true'
    
    app.run(debug=debug_mode, host='0.0.0.0', port=port, use_reloader=False)