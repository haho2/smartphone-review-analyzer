"""
ë°°ì¹˜ í¬ë¡¤ë§ ìŠ¤í¬ë¦½íŠ¸: ì œí’ˆë³„ ìœ íŠœë¸Œ ì˜ìƒê³¼ ì»¤ë®¤ë‹ˆí‹° í›„ê¸°ë¥¼ ë¯¸ë¦¬ ìˆ˜ì§‘í•˜ì—¬ MongoDBì— ì €ì¥
"""
import crawler
import database
import ai_service
import sys
import json
from datetime import datetime

# Windowsì—ì„œ UTF-8 ì¶œë ¥ì„ ìœ„í•œ ì„¤ì •
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

# í¬ë¡¤ë§í•  ì œí’ˆ ëª©ë¡ (product_normalizerì˜ VALID_MODELS ì°¸ì¡°)
import product_normalizer

# ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ëª¨ë¸ë§Œ í¬ë¡¤ë§ (í™˜ê° ë°©ì§€)
PRODUCTS_TO_CRAWL = product_normalizer.VALID_MODELS.copy()

def save_community_reviews_to_db(product_name, reviews_text, sources, actual_count=None):
    """
    ì œí’ˆë³„ ì»¤ë®¤ë‹ˆí‹° í›„ê¸°ë¥¼ MongoDBì— ì €ì¥
    
    Args:
        product_name: ì œí’ˆëª…
        reviews_text: í›„ê¸° í…ìŠ¤íŠ¸
        sources: ì†ŒìŠ¤ ë¦¬ìŠ¤íŠ¸
        actual_count: ì‹¤ì œ ìˆ˜ì§‘ëœ í›„ê¸° ê°œìˆ˜ (ì„ íƒì‚¬í•­)
    """
    try:
        from pymongo import MongoClient
        import os
        from dotenv import load_dotenv
        
        load_dotenv()
        load_dotenv(dotenv_path=os.path.join(os.path.dirname(__file__), '.env'))
        
        MONGODB_URI = os.getenv('MONGODB_URI', 'mongodb://localhost:27017/')
        DATABASE_NAME = os.getenv('MONGODB_DATABASE', 'youtube_reviews_db')
        COLLECTION_NAME = 'community_reviews'  # ìƒˆë¡œìš´ ì»¬ë ‰ì…˜
        
        client = MongoClient(MONGODB_URI, serverSelectionTimeoutMS=5000)
        db = client[DATABASE_NAME]
        collection = db[COLLECTION_NAME]
        
        current_timestamp = int(datetime.now().timestamp())
        
        # ì‹¤ì œ í›„ê¸° ê°œìˆ˜ ê³„ì‚° (ë¦¬ìŠ¤íŠ¸ ê¸¸ì´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì¤„ ìˆ˜ë¡œ ì¶”ì •)
        if actual_count is not None:
            review_count = actual_count
        elif reviews_text:
            # "[ì†ŒìŠ¤]"ë¡œ ì‹œì‘í•˜ëŠ” ì¤„ë§Œ ì¹´ìš´íŠ¸ (ì‹¤ì œ í›„ê¸° í•­ëª©)
            review_count = len([line for line in reviews_text.split('\n') if line.strip().startswith('[')])
        else:
            review_count = 0
        
        document = {
            'product_name': product_name,
            'reviews_text': reviews_text,
            'sources': sources,
            'review_count': review_count,
            'created_at': current_timestamp,
            'updated_at': current_timestamp
        }
        
        # ì œí’ˆëª…ìœ¼ë¡œ upsert
        collection.update_one(
            {'product_name': product_name},
            {'$set': document},
            upsert=True
        )
        
        print(f"   âœ… DB ì €ì¥ ì™„ë£Œ: {product_name} ({review_count}ê°œ í›„ê¸°)")
        client.close()
        return True
        
    except Exception as e:
        print(f"   âŒ DB ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        return False


def save_youtube_videos_to_db(product_name, videos_data):
    """
    ì œí’ˆë³„ ìœ íŠœë¸Œ ì˜ìƒ ì •ë³´ë¥¼ MongoDBì— ì €ì¥
    """
    try:
        from pymongo import MongoClient
        import os
        from dotenv import load_dotenv
        
        load_dotenv()
        load_dotenv(dotenv_path=os.path.join(os.path.dirname(__file__), '.env'))
        
        MONGODB_URI = os.getenv('MONGODB_URI', 'mongodb://localhost:27017/')
        DATABASE_NAME = os.getenv('MONGODB_DATABASE', 'youtube_reviews_db')
        COLLECTION_NAME = 'youtube_videos'  # ìœ íŠœë¸Œ ì˜ìƒ ì •ë³´ ì»¬ë ‰ì…˜
        
        client = MongoClient(MONGODB_URI, serverSelectionTimeoutMS=5000)
        db = client[DATABASE_NAME]
        collection = db[COLLECTION_NAME]
        
        current_timestamp = int(datetime.now().timestamp())
        
        document = {
            'product_name': product_name,
            'videos': videos_data,  # ì˜ìƒ ë¦¬ìŠ¤íŠ¸
            'video_count': len(videos_data),
            'created_at': current_timestamp,
            'updated_at': current_timestamp
        }
        
        # ì œí’ˆëª…ìœ¼ë¡œ upsert
        collection.update_one(
            {'product_name': product_name},
            {'$set': document},
            upsert=True
        )
        
        print(f"   âœ… ìœ íŠœë¸Œ ì˜ìƒ DB ì €ì¥ ì™„ë£Œ: {product_name} ({len(videos_data)}ê°œ ì˜ìƒ)")
        client.close()
        return True
        
    except Exception as e:
        print(f"   âŒ ìœ íŠœë¸Œ ì˜ìƒ DB ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        return False


def crawl_product_batch(product_name):
    """
    íŠ¹ì • ì œí’ˆì˜ ìœ íŠœë¸Œ ì˜ìƒê³¼ ì»¤ë®¤ë‹ˆí‹° í›„ê¸°ë¥¼ í¬ë¡¤ë§í•˜ì—¬ DBì— ì €ì¥ (ì œí’ˆëª… ì •ê·œí™” ì ìš©)
    """
    import product_normalizer
    
    # ì œí’ˆëª… ì •ê·œí™”
    normalized_name = product_normalizer.normalize_product_name(product_name)
    
    print(f"\n{'='*60}")
    print(f"ğŸ“± ì œí’ˆ í¬ë¡¤ë§ ì‹œì‘: {product_name}")
    if normalized_name != product_name:
        print(f"   â†’ ì •ê·œí™”: {product_name} -> {normalized_name}")
    print(f"{'='*60}")
    
    success = True
    
    try:
        # 1. ìœ íŠœë¸Œ ì˜ìƒ ê²€ìƒ‰ ë° ë¶„ì„
        print(f"   ğŸ¥ ìœ íŠœë¸Œ ì˜ìƒ ê²€ìƒ‰ ì¤‘...")
        youtube_videos = crawler.search_youtube_top3(normalized_name)
        
        if youtube_videos:
            print(f"      âœ… {len(youtube_videos)}ê°œ ì˜ìƒ ë°œê²¬")
            
            # ê° ì˜ìƒì— ëŒ€í•´ ìë§‰ ì¶”ì¶œ ë° AI ë¶„ì„ ìˆ˜í–‰
            analyzed_videos = []
            for video in youtube_videos:
                video_id = video['id']
                video_title = video['title']
                
                print(f"      ğŸ“¹ [{video_id}] {video_title[:50]}...")
                
                # DBì—ì„œ ì´ë¯¸ ë¶„ì„ëœ ì˜ìƒì¸ì§€ í™•ì¸
                cached_result = database.get_review_from_db(video_id)
                
                if cached_result:
                    print(f"         âš¡ ì´ë¯¸ ë¶„ì„ë¨ (ìºì‹œ íˆíŠ¸)")
                    analyzed_videos.append(video)
                else:
                    # ìë§‰ ì¶”ì¶œ ë° AI ë¶„ì„
                    print(f"         ğŸ”„ ìë§‰ ì¶”ì¶œ ë° AI ë¶„ì„ ì¤‘...")
                    script = ai_service.get_youtube_script(video_id)
                    
                    if script.startswith("âŒ"):
                        print(f"         âŒ ìë§‰ ì¶”ì¶œ ì‹¤íŒ¨: {script}")
                        analyzed_videos.append(video)  # ì˜ìƒ ì •ë³´ëŠ” ì €ì¥
                        continue
                    
                    analysis = ai_service.analyze_with_gemini(script)
                    
                    if isinstance(analysis, str) and analysis.startswith("âŒ"):
                        print(f"         âŒ AI ë¶„ì„ ì‹¤íŒ¨: {analysis}")
                        analyzed_videos.append(video)  # ì˜ìƒ ì •ë³´ëŠ” ì €ì¥
                        continue
                    
                    # ë¶„ì„ ê²°ê³¼ DBì— ì €ì¥
                    import json
                    if isinstance(analysis, dict):
                        database.save_review_to_db(video_id, json.dumps(analysis, ensure_ascii=False))
                    else:
                        database.save_review_to_db(video_id, analysis)
                    
                    print(f"         âœ… ë¶„ì„ ì™„ë£Œ ë° ì €ì¥")
                    analyzed_videos.append(video)
            
            # ì˜ìƒ ì •ë³´ ì €ì¥
            save_youtube_videos_to_db(normalized_name, analyzed_videos)
        else:
            print(f"      âš ï¸ ìœ íŠœë¸Œ ì˜ìƒì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            success = False
        
        # 2. ì»¤ë®¤ë‹ˆí‹° í›„ê¸° í¬ë¡¤ë§ ë° ì €ì¥
        print(f"   ğŸ’¬ ì»¤ë®¤ë‹ˆí‹° í›„ê¸° í¬ë¡¤ë§ ì¤‘...")
        result = crawler.crawl_community_reviews(normalized_name)
        
        if isinstance(result, tuple):
            if len(result) == 3:
                reviews_text, sources, actual_count = result
            else:
                reviews_text, sources = result
                actual_count = None
        else:
            reviews_text = result
            sources = []
            actual_count = None
        
        if reviews_text and "ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤" not in reviews_text:
            # DBì— ì €ì¥ (ì •ê·œí™”ëœ ì œí’ˆëª…ìœ¼ë¡œ ì €ì¥)
            save_community_reviews_to_db(normalized_name, reviews_text, sources, actual_count)
            
            # ì»¤ë®¤ë‹ˆí‹° í›„ê¸° AI ë¶„ì„ ìˆ˜í–‰ ë° ì €ì¥
            print(f"   ğŸ¤– ì»¤ë®¤ë‹ˆí‹° í›„ê¸° AI ë¶„ì„ ì¤‘...")
            community_analysis = ai_service.analyze_community_reviews_with_gemini(reviews_text)
            
            if isinstance(community_analysis, str) and community_analysis.startswith("âŒ"):
                print(f"      âŒ ì»¤ë®¤ë‹ˆí‹° ë¶„ì„ ì‹¤íŒ¨: {community_analysis}")
            else:
                # ë¶„ì„ ê²°ê³¼ DBì— ì €ì¥
                save_community_analysis_to_db(normalized_name, community_analysis)
                print(f"      âœ… ì»¤ë®¤ë‹ˆí‹° ë¶„ì„ ì™„ë£Œ ë° ì €ì¥")
        else:
            print(f"   âš ï¸ {normalized_name}: ì»¤ë®¤ë‹ˆí‹° í›„ê¸°ë¥¼ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            success = False
        
        return success
            
    except Exception as e:
        print(f"   âŒ {normalized_name} í¬ë¡¤ë§ ì‹¤íŒ¨: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def get_youtube_videos_from_db(product_name):
    """
    MongoDBì—ì„œ ì œí’ˆë³„ ìœ íŠœë¸Œ ì˜ìƒ ì •ë³´ ì¡°íšŒ (ì œí’ˆëª… ë³€í˜• ìë™ ì²˜ë¦¬)
    """
    try:
        import product_normalizer
        from pymongo import MongoClient
        import os
        from dotenv import load_dotenv
        
        load_dotenv()
        load_dotenv(dotenv_path=os.path.join(os.path.dirname(__file__), '.env'))
        
        MONGODB_URI = os.getenv('MONGODB_URI', 'mongodb://localhost:27017/')
        DATABASE_NAME = os.getenv('MONGODB_DATABASE', 'youtube_reviews_db')
        COLLECTION_NAME = 'youtube_videos'
        
        client = MongoClient(MONGODB_URI, serverSelectionTimeoutMS=5000)
        db = client[DATABASE_NAME]
        collection = db[COLLECTION_NAME]
        
        # ì •ê·œí™”ëœ ì œí’ˆëª…ìœ¼ë¡œ ë¨¼ì € ê²€ìƒ‰
        normalized_name = product_normalizer.normalize_product_name(product_name)
        result = collection.find_one({'product_name': normalized_name})
        
        if result:
            videos = result.get('videos', [])
            client.close()
            return videos
        
        # ì •í™•íˆ ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ ìœ ì‚¬ ì œí’ˆëª… ê²€ìƒ‰
        all_products = collection.find({}, {'product_name': 1})
        db_product_names = [p['product_name'] for p in all_products]
        
        similar_product = product_normalizer.find_similar_product_in_db(product_name, db_product_names)
        
        if similar_product:
            print(f"   ğŸ” ìœ ì‚¬ ì œí’ˆëª… ë°œê²¬: '{product_name}' -> '{similar_product}'")
            result = collection.find_one({'product_name': similar_product})
            if result:
                videos = result.get('videos', [])
                client.close()
                return videos
        
        client.close()
        return None
            
    except Exception as e:
        print(f"   âš ï¸ ìœ íŠœë¸Œ ì˜ìƒ DB ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        return None


def get_community_reviews_from_db(product_name):
    """
    MongoDBì—ì„œ ì œí’ˆë³„ ì»¤ë®¤ë‹ˆí‹° í›„ê¸° ì¡°íšŒ (ì œí’ˆëª… ë³€í˜• ìë™ ì²˜ë¦¬)
    ë¶„ì„ ê²°ê³¼ë„ í•¨ê»˜ ë°˜í™˜ (ìºì‹±ëœ ê²½ìš°)
    """
    try:
        import product_normalizer
        from pymongo import MongoClient
        import os
        from dotenv import load_dotenv
        
        load_dotenv()
        load_dotenv(dotenv_path=os.path.join(os.path.dirname(__file__), '.env'))
        
        MONGODB_URI = os.getenv('MONGODB_URI', 'mongodb://localhost:27017/')
        DATABASE_NAME = os.getenv('MONGODB_DATABASE', 'youtube_reviews_db')
        COLLECTION_NAME = 'community_reviews'
        
        client = MongoClient(MONGODB_URI, serverSelectionTimeoutMS=5000)
        db = client[DATABASE_NAME]
        collection = db[COLLECTION_NAME]
        
        # ì •ê·œí™”ëœ ì œí’ˆëª…ìœ¼ë¡œ ë¨¼ì € ê²€ìƒ‰
        normalized_name = product_normalizer.normalize_product_name(product_name)
        result = collection.find_one({'product_name': normalized_name})
        
        if result:
            reviews_text = result.get('reviews_text', '')
            sources = result.get('sources', [])
            analysis_summary = result.get('analysis_summary', None)  # ìºì‹±ëœ ë¶„ì„ ê²°ê³¼
            client.close()
            return reviews_text, sources, analysis_summary
        
        # ì •í™•íˆ ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ ëª¨ë“  ì œí’ˆëª… ê°€ì ¸ì™€ì„œ ìœ ì‚¬ë„ ê²€ìƒ‰
        all_products = collection.find({}, {'product_name': 1})
        db_product_names = [p['product_name'] for p in all_products]
        
        similar_product = product_normalizer.find_similar_product_in_db(product_name, db_product_names)
        
        if similar_product:
            print(f"   ğŸ” ìœ ì‚¬ ì œí’ˆëª… ë°œê²¬: '{product_name}' -> '{similar_product}'")
            result = collection.find_one({'product_name': similar_product})
            if result:
                reviews_text = result.get('reviews_text', '')
                sources = result.get('sources', [])
                analysis_summary = result.get('analysis_summary', None)  # ìºì‹±ëœ ë¶„ì„ ê²°ê³¼
                client.close()
                return reviews_text, sources, analysis_summary
        
        client.close()
        return None, [], None
            
    except Exception as e:
        print(f"   âš ï¸ DB ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        return None, [], None


def save_community_analysis_to_db(product_name, analysis_summary):
    """
    ì œí’ˆë³„ ì»¤ë®¤ë‹ˆí‹° í›„ê¸° AI ë¶„ì„ ê²°ê³¼ë¥¼ MongoDBì— ì €ì¥ (ìºì‹±)
    """
    try:
        from pymongo import MongoClient
        import os
        from dotenv import load_dotenv
        import json
        
        load_dotenv()
        load_dotenv(dotenv_path=os.path.join(os.path.dirname(__file__), '.env'))
        
        MONGODB_URI = os.getenv('MONGODB_URI', 'mongodb://localhost:27017/')
        DATABASE_NAME = os.getenv('MONGODB_DATABASE', 'youtube_reviews_db')
        COLLECTION_NAME = 'community_reviews'
        
        client = MongoClient(MONGODB_URI, serverSelectionTimeoutMS=5000)
        db = client[DATABASE_NAME]
        collection = db[COLLECTION_NAME]
        
        # ë¶„ì„ ê²°ê³¼ë¥¼ JSON ë¬¸ìì—´ë¡œ ë³€í™˜
        if isinstance(analysis_summary, dict):
            analysis_json = json.dumps(analysis_summary, ensure_ascii=False)
        else:
            analysis_json = str(analysis_summary)
        
        # ì œí’ˆëª…ìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ ì—…ë°ì´íŠ¸
        collection.update_one(
            {'product_name': product_name},
            {'$set': {'analysis_summary': analysis_json, 'analysis_updated_at': int(datetime.now().timestamp())}},
            upsert=False  # ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ë¬¸ì„œë§Œ ì—…ë°ì´íŠ¸
        )
        
        print(f"   âœ… ì»¤ë®¤ë‹ˆí‹° ë¶„ì„ ê²°ê³¼ ìºì‹œ ì €ì¥ ì™„ë£Œ: {product_name}")
        client.close()
        return True
        
    except Exception as e:
        print(f"   âš ï¸ ë¶„ì„ ê²°ê³¼ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        return False


if __name__ == "__main__":
    print("ğŸš€ ë°°ì¹˜ í¬ë¡¤ë§ ì‹œì‘")
    print(f"ì´ {len(PRODUCTS_TO_CRAWL)}ê°œ ì œí’ˆ í¬ë¡¤ë§ ì˜ˆì •\n")
    
    success_count = 0
    fail_count = 0
    
    for product in PRODUCTS_TO_CRAWL:
        if crawl_product_batch(product):
            success_count += 1
        else:
            fail_count += 1
    
    print(f"\n{'='*60}")
    print(f"âœ… ì™„ë£Œ: {success_count}ê°œ ì„±ê³µ, âŒ ì‹¤íŒ¨: {fail_count}ê°œ")
    print(f"{'='*60}")

